{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张老师新给损失函数实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载各种包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import tree \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.io as scio\n",
    "# import hiddenlayer as h\n",
    "from visdom import Visdom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "import sys\n",
    "from utils.reuse import *\n",
    "from utils.networks import *\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备操作\n",
    "设置检查点、visdom 日志文件存储等日志性文件存储位置；\n",
    "初始化 visdom,记得先在命令行输入 visdom 运行（python环境下）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_04_10_19_19_27\n"
     ]
    }
   ],
   "source": [
    "# 以下是检查点路径\n",
    "# 请在当前环境下 CMD 输入python -m visdom.server 或 visdom 启动监视器\n",
    "# 数据处理现在已移至 emgDataprocess.ipynb\n",
    "model_Dir = './/model//emgmk_cnn_0410_nl//'\n",
    "if not os.path.exists(model_Dir):\n",
    "    os.makedirs(model_Dir)\n",
    "\n",
    "ckpDir = model_Dir+'ckp//'\n",
    "if not os.path.exists(ckpDir):\n",
    "    os.makedirs(ckpDir)\n",
    "\n",
    "ckpDir_auc = './/ckp//emgmk_cnn_0323_nl//auc//'\n",
    "if not os.path.exists(ckpDir_auc):\n",
    "    os.makedirs(ckpDir_auc)\n",
    "\n",
    "def get_current_time():\n",
    "    return datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "print(get_current_time())\n",
    "\n",
    "timeForSave = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visdom has started\n"
     ]
    }
   ],
   "source": [
    "# 以下是 visdom 监视窗口初始化，实现每次启用时重新加载，这里只写了 NameError 以防其他错误不能被发现\n",
    "class visdom_account:\n",
    "    def __init__(self):    \n",
    "        self.port = 8097\n",
    "        self.server = \"http://localhost\"\n",
    "        self.base_url = \"/\"\n",
    "        self.username = \"admin\"\n",
    "        self.passward = \"1234\"\n",
    "        self.evns = \"train4\"\n",
    "viz_acnt = visdom_account()\n",
    "vislogDir = model_Dir+'vislog//'\n",
    "if not os.path.exists(vislogDir):\n",
    "    os.makedirs(vislogDir)\n",
    "def viz_init():\n",
    "    try:\n",
    "        viz\n",
    "    except NameError:\n",
    "        viz = Visdom(env=viz_acnt.evns,log_to_filename=vislogDir+'vislog_'+timeForSave)\n",
    "        print('visdom has started')\n",
    "    else:\n",
    "        viz.close()\n",
    "        del viz\n",
    "        print('last visdom session closed')\n",
    "        viz = Visdom(env=viz_acnt.evns,log_to_filename=vislogDir+'vislog_'+timeForSave)\n",
    "        print('visdom has restarted')\n",
    "    return viz\n",
    "viz = viz_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义神经网络结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [1, 128, 1, 6]           1,280\n",
      "            Linear-2                   [1, 128]          98,432\n",
      "            Linear-3                   [1, 128]          16,512\n",
      "            Linear-4                     [1, 6]             774\n",
      "================================================================\n",
      "Total params: 116,998\n",
      "Trainable params: 116,998\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 0.45\n",
      "----------------------------------------------------------------\n",
      "Outputshape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# 自定义神经网络,CNN\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "# hdreshape = 32*1*3\n",
    "hdreshape = 2\n",
    "hdlayer_1 = 16\n",
    "hdlayer_2 = 16\n",
    "hdlayer_3 = 256\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128,\\\n",
    "             kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32,\\\n",
    "             kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, \\\n",
    "            kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=128*1*6, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
    "        # self.fc3 = nn.Linear(in_features=hdlayer_2, out_features=hdlayer_3)\n",
    "        self.out = nn.Linear(in_features=128, out_features=6)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        # t = t.reshape(1,1,3)\n",
    "        # t = t.unsqueeze(0)\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        # t = self.conv2(t)\n",
    "        # t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 128*1*6)\n",
    "        # t = t.flatten(start_dim=0)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        # t = self.fc3(t)\n",
    "        # t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "\n",
    "        # (5) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "net = Network()\n",
    "# 打印网络，检查输入输出 shape是否正确\n",
    "# print(net)\n",
    "samplebatchsize = 1\n",
    "summary(net,(1,1,6),batch_size = samplebatchsize,device = \"cpu\")\n",
    "sampleInput = torch.randn(samplebatchsize,1,1,6).requires_grad_(True)\n",
    "sampleOutput = net(sampleInput)\n",
    "print('Outputshape:',sampleOutput.shape)\n",
    "# framevision = make_dot(sampleOutput, params=dict(list(net.named_parameters()) + [('x',sampleInput)]))\n",
    "# framevision.format = \"png\"\n",
    "# framevision.direcory = \"./\"\n",
    "# framevision.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载、构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataarray = np.load('../data/WristDataForPINN-1/EMGSKdata-220409.npy',allow_pickle=True)\n",
    "CNNdataset = dataarray.item()\n",
    "print(type(CNNdataset))\n",
    "# 加载自变量：因为数据头尾不少空缺，裁剪之\n",
    "data_head = 11\n",
    "data_end = 2000\n",
    "data_time = CNNdataset['time'][data_head:data_end]\n",
    "data_fcr= CNNdataset['fcr'][data_head:data_end]\n",
    "data_fcu = CNNdataset['fcu'][data_head:data_end]\n",
    "data_ecrl = CNNdataset['ecrl'][data_head:data_end]\n",
    "data_ecrb = CNNdataset['ecrb'][data_head:data_end]\n",
    "data_ecu = CNNdataset['ecu'][data_head:data_end]\n",
    "data_angle = CNNdataset['angle'][data_head:data_end]\n",
    "data_mf_fcr = CNNdataset['mf_fcr'][data_head:data_end]\n",
    "data_mf_fcu = CNNdataset['mf_fcu'][data_head:data_end]\n",
    "data_mf_ecrl = CNNdataset['mf_ecrl'][data_head:data_end]\n",
    "data_mf_ecrb = CNNdataset['mf_ecrb'][data_head:data_end]\n",
    "data_mf_ecu = CNNdataset['mf_ecu'][data_head:data_end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1592, 1) (397, 1)\n",
      "torch.Size([1592, 6]) torch.Size([1592, 6]) torch.Size([397, 6]) torch.Size([397, 6])\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集与测试集，每5点抽取一点作为测试集\n",
    "def DataSpliter(data):\n",
    "    data_tr = []\n",
    "    data_te = []\n",
    "    for i in range(len(data)):\n",
    "        if (i+1)%5 == 0:\n",
    "            data_te.append(data[i,:])\n",
    "        else:\n",
    "            data_tr.append(data[i,:])\n",
    "    data_tr = np.array(data_tr)\n",
    "    data_te = np.array(data_te)\n",
    "    return data_tr, data_te\n",
    "# 自变量部分\n",
    "tr_data_time,te_data_time = DataSpliter(data_time)\n",
    "tr_data_fcr,te_data_fcr = DataSpliter(data_fcr)\n",
    "tr_data_fcu,te_data_fcu = DataSpliter(data_fcu)\n",
    "tr_data_ecrl,te_data_ecrl = DataSpliter(data_ecrl)\n",
    "tr_data_ecrb,te_data_ecrb = DataSpliter(data_ecrb)\n",
    "tr_data_ecu,te_data_ecu = DataSpliter(data_ecu)\n",
    "# 因变量部分\n",
    "tr_data_angle,te_data_angle = DataSpliter(data_angle)\n",
    "tr_data_mf_fcr,te_data_mf_fcr = DataSpliter(data_mf_fcr)\n",
    "tr_data_mf_fcu,te_data_mf_fcu = DataSpliter(data_mf_fcu)\n",
    "tr_data_mf_ecrl,te_data_mf_ecrl = DataSpliter(data_mf_ecrl)\n",
    "tr_data_mf_ecrb,te_data_mf_ecrb = DataSpliter(data_mf_ecrb)\n",
    "tr_data_mf_ecu,te_data_mf_ecu = DataSpliter(data_mf_ecu)\n",
    "print(tr_data_mf_ecu.shape,te_data_ecu.shape)\n",
    "# 按需组合数据，这两函数其实可以合并成一个\n",
    "def Data_conbine(data_1,data_2,data_3,data_4,data_5,data_6):\n",
    "    data_train = []\n",
    "    for i in range(len(data_1)):\n",
    "        data_1t6 = np.hstack((data_1[i,:],data_2[i,:],data_3[i,:]\\\n",
    "            ,data_4[i,:],data_5[i,:],data_6[i,:]))\n",
    "        data_1t6 = data_1t6.flatten()\n",
    "        data_train.append(data_1t6)\n",
    "    data_train = np.array(data_train)\n",
    "    return data_train\n",
    "# 多时间步组建数据，这个在这里暂时没用上，因此我把它暂时注掉了\n",
    "# def establish_multi_timestep_data(data_X,data_X_2,data_Y,expect_time_length):\n",
    "#     dataset = []\n",
    "#     dataset_y = []\n",
    "#     if expect_time_length >0:\n",
    "#         length = len(data_X)-expect_time_length\n",
    "#         for i in range(length):\n",
    "#             data_1 = data_X[i:i+expect_time_length,:]\n",
    "#             data_1 = data_1.flatten()\n",
    "#             data_2 = data_X_2[i:i+expect_time_length,:]\n",
    "#             data_2 = data_2.flatten()\n",
    "#             data_12 = np.hstack((data_1,data_2))\n",
    "#             dataset.append(data_12)\n",
    "#             dataset_y.append(data_Y[i+expect_time_length-1,:])\n",
    "#         dataset = np.array(dataset)\n",
    "#         dataset_y = np.array(dataset_y)\n",
    "#     return dataset, dataset_y\n",
    "# 将自变量与因变量各自组合到一起，尺寸均为1*6\n",
    "data_1t6_tr = Data_conbine(tr_data_time,tr_data_fcr,tr_data_fcu\\\n",
    "    ,tr_data_ecrl,tr_data_ecrb,tr_data_ecu)\n",
    "data_1t6_te = Data_conbine(te_data_time,te_data_fcr,te_data_fcu\\\n",
    "    ,te_data_ecrl,te_data_ecrb,te_data_ecu)\n",
    "data_7t12_tr = Data_conbine(tr_data_angle,tr_data_mf_fcr,tr_data_mf_fcu\\\n",
    "    ,tr_data_mf_ecrl,tr_data_mf_ecrb,tr_data_mf_ecu)\n",
    "data_7t12_te = Data_conbine(te_data_angle,te_data_mf_fcr,te_data_mf_fcu\\\n",
    "    ,te_data_mf_ecrl,te_data_mf_ecrb,te_data_mf_ecu)\n",
    "# 转为 tensor 格式\n",
    "data_1t6_tr = torch.from_numpy(data_1t6_tr).to(torch.float32)\n",
    "data_1t6_te = torch.from_numpy(data_1t6_te).to(torch.float32)\n",
    "data_7t12_tr = torch.from_numpy(data_7t12_tr).to(torch.float32)\n",
    "data_7t12_te = torch.from_numpy(data_7t12_te).to(torch.float32)\n",
    "\n",
    "print(data_1t6_tr.shape,data_7t12_tr.shape,data_1t6_te.shape,\\\n",
    "    data_7t12_te.shape)\n",
    "\n",
    "# # 需要一个指示前一时刻的标签，居然没注意到 cyc 每五取一后不再连续了，害\n",
    "data_index_tr = np.linspace(0,1591,1592)\n",
    "data_index_te = np.linspace(0,396,397)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iterator object at 0x000001B57E56D880>\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "])\n",
    "class EMGSK_Dataset(Dataset):\n",
    " \n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index,:]\n",
    "        sample_y = self.data_y[index,:]\n",
    "        # for CNN\n",
    "        sample_x = sample_x.unsqueeze(0)\n",
    "        sample_x = sample_x.numpy()\n",
    "        sample_x = self.transforms(sample_x)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)     \n",
    "        return sample_x,sample_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "class EMGSK_nl_Dataset(Dataset):\n",
    " \n",
    "    def __init__(self, data_x, data_y,data_idx):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data_angle = self.data_y[:,0]\n",
    "        self.data_time = self.data_x[:,0]\n",
    "        self.data_idx = data_idx\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index,:]\n",
    "        sample_y = self.data_y[index,:]\n",
    "        sample_angle = self.data_angle[index]\n",
    "        sample_time = self.data_time[index]\n",
    "        sample_idx = self.data_idx[index]\n",
    "        # for CNN\n",
    "        sample_x = sample_x.unsqueeze(0)\n",
    "        sample_x = sample_x.numpy()\n",
    "        sample_x = self.transforms(sample_x)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)     \n",
    "        return sample_x,sample_y,sample_angle,sample_time,\\\n",
    "            sample_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "train_set = EMGSK_nl_Dataset(data_1t6_tr,data_7t12_tr,\\\n",
    "    data_index_tr)\n",
    "test_set = EMGSK_nl_Dataset(data_1t6_te,data_7t12_te,\\\n",
    "    data_index_te)\n",
    "\n",
    "sample = iter(test_set)\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=2,shuffle=False)\n",
    "# batch1 = iter(train_loader)\n",
    "# dassy_2 = data_457_tr_y[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 1, 1, 6]) tensor([[[[0.0130, 0.0175, 0.0704, 0.0133, 0.0006, 0.0094]]],\n",
      "\n",
      "\n",
      "        [[[0.0140, 0.0187, 0.0717, 0.0137, 0.0008, 0.0100]]]]) \n",
      " y: torch.Size([2, 6]) tensor([[ 0.3228,  8.5777, 44.4146, 10.4225,  0.2382,  4.4142],\n",
      "        [ 0.3249,  9.1827, 45.1840, 10.7714,  0.3259,  4.7043]]) \n",
      " a: torch.Size([2]) tensor([0.3228, 0.3249]) \n",
      " t: torch.Size([2]) tensor([0.0130, 0.0140]) \n",
      " idx: torch.Size([2]) tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# batch2 = next(batch1)\n",
    "# d_x,d_y,d_a,d_t,d_i= batch2\n",
    "# print('x:',d_x.shape,d_x,'\\n','y:',d_y.shape,d_y,'\\n',\\\n",
    "#     'a:',d_a.shape,d_a,'\\n','t:',d_t.shape,d_t,'\\n',\\\n",
    "#         'idx:',d_i.shape,d_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数实现\n",
    "动量公式：一共要计算 5 种力，所以求和为 5 个\n",
    "$$\n",
    "\\sum_1^5{F_i * Ma} = I* \\ddot{\\theta} + B * \\dot{\\theta} + mglsin\\theta\n",
    "$$\n",
    "与 MSE 配合使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 loss 时需要注意所有的 tensor 操作都应该在 torch 工具包里面出现，\n",
    "# 当然了基本的加减乘除不用，参考：https://blog.csdn.net/bornfree5511/\n",
    "# article/details/104118437?utm_medium=distribute.pc_relevant.\n",
    "# none-task-blog-2~default~baidujs_title~default-0.pc_relevant_aa&spm\n",
    "# =1001.2101.3001.4242.1&utm_relevant_index=3，\n",
    "# 当然我已经将它复制到一个 excel 并转为 pdf 永久保存了，看哪个都一样\n",
    "class LossMSE3(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(LossMSE3,self).__init__()\n",
    "        self.Loss_MSE = torch.nn.MSELoss()\n",
    "        self.pred_angle_list = [torch.tensor([],requires_grad=False) \\\n",
    "        for i in range(1592)]\n",
    "        self.time_list = [torch.tensor([],requires_grad=False) \\\n",
    "        for i in range(1592)]\n",
    "        self.vel_list = [torch.tensor([],requires_grad=False) \\\n",
    "        for i in range(1592)]\n",
    "        # 由于进行了数据裁剪，现在可以计算出初始阶段的速度和加速度了\n",
    "        self.t_b1 = 0.01\n",
    "        self.t_b2 = 0.09\n",
    "        self.a_b1 = 0.3163\n",
    "        self.a_b2 = 0.3142\n",
    "        self.v_b1 = (self.a_b1 - self.a_b2)/(self.t_b1 - self.t_b2)\n",
    "        self.I = (-13.68+0.088*78+0.092*178)/10000\n",
    "        self.mgl = 0.477*0.08*9.8\n",
    "        self.B = 0.3\n",
    "\n",
    "\n",
    "    def forward(self,preds,s_y,s_time,s_idx):\n",
    "        # p1 = angle, p2 = mf_fcr, p3 = mf_fcu, p4 = mf_ecrl,\n",
    "        # p5 = mf_ecrb, p6 = mf_ecu\n",
    "        p1,p2,p3,p4,p5,p6 = torch.chunk(preds,6,1)\n",
    "\n",
    "        s_time.requires_grad_(False)\n",
    "        s_idx.requires_grad_(False)\n",
    "        # 第一时刻的速度和加速度，要借助前一时刻的时间和速度数据，这需要导入原始数据的部分，\n",
    "        # 之后的就不需要了\n",
    "        if s_idx == 0:\n",
    "            p_a = float(p1)\n",
    "            self.pred_angle_list[int(s_idx)] = p_a\n",
    "            s_tt = float(s_time)\n",
    "            self.time_list[int(s_idx)] = s_tt\n",
    "            s_angle_p = self.a_b1\n",
    "            s_time_p = self.t_b1\n",
    "            s_v = (p1.to(device) - s_angle_p) / (s_time.to(device) - s_time_p)\n",
    "            s_vv = float(s_v)\n",
    "            self.vel_list[int(s_idx)] = s_vv\n",
    "            s_v_p = self.v_b1\n",
    "            s_a = (s_v - s_v_p)/ (s_time.to(device) - s_time_p)\n",
    "        else:\n",
    "            # 当前值存入列表备用，同时取出前一刻角度值计算速度与加速度\n",
    "            p_a = float(p1)\n",
    "            self.pred_angle_list[int(s_idx)] = p_a\n",
    "            s_tt = float(s_time)\n",
    "            self.time_list[int(s_idx)] = s_tt\n",
    "            s_angle_p = self.pred_angle_list[int(s_idx)-1]\n",
    "            s_time_p = self.time_list[int(s_idx)-1]\n",
    "            s_v = (p1.to(device) - s_angle_p) / (s_time.to(device) - s_time_p)\n",
    "            s_vv = float(s_v)\n",
    "            self.vel_list[int(s_idx)] = s_vv\n",
    "            s_v_p = self.vel_list[int(s_idx)-1]\n",
    "            s_a = (s_v - s_v_p)/ (s_time.to(device) - s_time_p)\n",
    "        \n",
    "        # 接下来计算每个力对应的力臂，直接调用公式，没什么可说的\n",
    "        MA_fcr = - (3732599*np.cos((1937*p_a)/5000))/250000000 - (2756351*np.sin((1937*p_a)/5000))/500000000\n",
    "        MA_fcu = - (1495713*np.cos((1227*p_a)/5000))/100000000 - (3056457*np.sin((1227*p_a)/5000))/250000000\n",
    "        MA_ecrl = (10071157*np.cos((7499*p_a)/100000))/1000000000 - (34952839*np.sin((7499*p_a)/100000))/1000000000\n",
    "        MA_ecrb = (332459*np.cos((1069*p_a)/5000))/25000000 - (5230617*np.sin((1069*p_a)/5000))/500000000\n",
    "        MA_ecu_bfer1 = np.cos((1213*p_a)/1000)\n",
    "        MA_ecu_bfer2 = np.sin((1213*p_a)/1000)\n",
    "        MA_ecu = (3833970711819040.923)*MA_ecu_bfer1/576460752303423488 + \\\n",
    "            (783715917163374.201*MA_ecu_bfer2)/4611686018427387904\n",
    "        \n",
    "        # 实现整个公式，公式左边的部分要放到右边来，所以每个项前面都有负号\n",
    "        new_loss = self.I * s_a + self.B * s_v+ self.mgl * torch.sin(p1.to(device)) - \\\n",
    "            (p2.to(device) * MA_fcr) - (p3.to(device) * MA_fcu) - \\\n",
    "                (p4.to(device) * MA_ecrl) - (p5.to(device) * MA_ecrb) -\\\n",
    "                    (p6.to(device) * MA_ecu)\n",
    "        old_loss = self.Loss_MSE(preds,s_y)\n",
    "        loss = new_loss+old_loss\n",
    "\n",
    "        return loss\n",
    "new_loss3 = LossMSE3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visdom has started\n",
      "epoch 1 MSE_tr: 1632103.0\n",
      "epoch 2 MSE_tr: 1631478.875\n",
      "epoch 3 MSE_tr: 1631043.375\n",
      "epoch 4 MSE_tr: 1629853.125\n",
      "epoch 5 MSE_tr: 1629194.25\n",
      "epoch 6 MSE_tr: 1628776.875\n",
      "epoch 7 MSE_tr: 1628287.0\n",
      "epoch 8 MSE_tr: 1627149.375\n",
      "epoch 9 MSE_tr: 1626317.75\n",
      "epoch 10 MSE_tr: 1626413.5\n",
      "epoch 11 MSE_tr: 1627158.375\n",
      "epoch 12 MSE_tr: 1625558.625\n",
      "epoch 13 MSE_tr: 1625035.0\n",
      "epoch 14 MSE_tr: 1624971.375\n",
      "epoch 15 MSE_tr: 1624694.125\n",
      "epoch 16 MSE_tr: 1624624.125\n",
      "epoch 17 MSE_tr: 1623393.125\n",
      "epoch 18 MSE_tr: 1624168.25\n",
      "epoch 19 MSE_tr: 1623656.375\n",
      "epoch 20 MSE_tr: 1622663.0\n",
      "epoch 21 MSE_tr: 1623446.125\n",
      "epoch 22 MSE_tr: 1622993.5\n",
      "epoch 23 MSE_tr: 1623094.75\n",
      "epoch 24 MSE_tr: 1622408.25\n",
      "epoch 25 MSE_tr: 1621466.0\n",
      "epoch 26 MSE_tr: 1622213.375\n",
      "epoch 27 MSE_tr: 1621837.5\n",
      "epoch 28 MSE_tr: 1622205.125\n",
      "epoch 29 MSE_tr: 1620954.25\n",
      "epoch 30 MSE_tr: 1621202.5\n",
      "epoch 31 MSE_tr: 1621179.25\n",
      "epoch 32 MSE_tr: 1620108.375\n",
      "epoch 33 MSE_tr: 1620337.5\n",
      "epoch 34 MSE_tr: 1620299.25\n",
      "epoch 35 MSE_tr: 1620028.75\n",
      "epoch 36 MSE_tr: 1620184.375\n",
      "epoch 37 MSE_tr: 1620250.375\n",
      "epoch 38 MSE_tr: 1620559.5\n",
      "epoch 39 MSE_tr: 1619710.375\n",
      "epoch 40 MSE_tr: 1619681.0\n",
      "epoch 41 MSE_tr: 1620137.75\n",
      "epoch 42 MSE_tr: 1620502.125\n",
      "epoch 43 MSE_tr: 1619486.25\n",
      "epoch 44 MSE_tr: 1619149.375\n",
      "epoch 45 MSE_tr: 1618598.0\n",
      "epoch 46 MSE_tr: 1618373.375\n",
      "epoch 47 MSE_tr: 1619049.75\n",
      "epoch 48 MSE_tr: 1617884.375\n",
      "epoch 49 MSE_tr: 1619340.25\n",
      "epoch 50 MSE_tr: 1619766.0\n",
      "epoch 51 MSE_tr: 1618267.375\n",
      "epoch 52 MSE_tr: 1619413.0\n",
      "epoch 53 MSE_tr: 1618791.75\n",
      "epoch 54 MSE_tr: 1619341.375\n",
      "epoch 55 MSE_tr: 1619296.75\n",
      "epoch 56 MSE_tr: 1618862.5\n",
      "epoch 57 MSE_tr: 1618446.5\n",
      "epoch 58 MSE_tr: 1617841.875\n",
      "epoch 59 MSE_tr: 1619081.875\n",
      "epoch 60 MSE_tr: 1618320.0\n",
      "epoch 61 MSE_tr: 1618494.625\n",
      "epoch 62 MSE_tr: 1619408.375\n",
      "epoch 63 MSE_tr: 1618098.875\n",
      "epoch 64 MSE_tr: 1617363.875\n",
      "epoch 65 MSE_tr: 1618209.25\n",
      "epoch 66 MSE_tr: 1618010.0\n",
      "epoch 67 MSE_tr: 1618283.625\n",
      "epoch 68 MSE_tr: 1618612.75\n",
      "epoch 69 MSE_tr: 1617924.875\n",
      "epoch 70 MSE_tr: 1618779.875\n",
      "epoch 71 MSE_tr: 1617680.625\n",
      "epoch 72 MSE_tr: 1618828.75\n",
      "epoch 73 MSE_tr: 1619230.75\n",
      "epoch 74 MSE_tr: 1618719.0\n",
      "epoch 75 MSE_tr: 1619035.0\n",
      "epoch 76 MSE_tr: 1617531.125\n",
      "epoch 77 MSE_tr: 1618435.75\n",
      "epoch 78 MSE_tr: 1618915.125\n",
      "epoch 79 MSE_tr: 1618116.375\n",
      "epoch 80 MSE_tr: 1617864.625\n",
      "epoch 81 MSE_tr: 1618189.625\n",
      "epoch 82 MSE_tr: 1618146.625\n",
      "epoch 83 MSE_tr: 1617303.0\n",
      "epoch 84 MSE_tr: 1618554.75\n",
      "epoch 85 MSE_tr: 1617680.0\n",
      "epoch 86 MSE_tr: 1618271.125\n",
      "epoch 87 MSE_tr: 1618601.375\n",
      "epoch 88 MSE_tr: 1618260.875\n",
      "epoch 89 MSE_tr: 1618536.0\n",
      "epoch 90 MSE_tr: 1617946.875\n",
      "epoch 91 MSE_tr: 1616919.875\n",
      "epoch 92 MSE_tr: 1616824.125\n",
      "epoch 93 MSE_tr: 1617322.25\n",
      "epoch 94 MSE_tr: 1617191.25\n",
      "epoch 95 MSE_tr: 1617067.625\n",
      "epoch 96 MSE_tr: 1617237.625\n",
      "epoch 97 MSE_tr: 1617447.5\n",
      "epoch 98 MSE_tr: 1616671.875\n",
      "epoch 99 MSE_tr: 1616398.375\n",
      "epoch 100 MSE_tr: 1617134.0\n",
      "epoch 101 MSE_tr: 1617987.625\n",
      "epoch 102 MSE_tr: 1617808.75\n",
      "epoch 103 MSE_tr: 1617430.75\n",
      "epoch 104 MSE_tr: 1617424.625\n",
      "epoch 105 MSE_tr: 1617228.5\n",
      "epoch 106 MSE_tr: 1617442.125\n",
      "epoch 107 MSE_tr: 1617376.0\n",
      "epoch 108 MSE_tr: 1616906.5\n",
      "epoch 109 MSE_tr: 1617047.875\n",
      "epoch 110 MSE_tr: 1617302.625\n",
      "epoch 111 MSE_tr: 1617251.5\n",
      "epoch 112 MSE_tr: 1616736.0\n",
      "epoch 113 MSE_tr: 1618015.25\n",
      "epoch 114 MSE_tr: 1617628.75\n",
      "epoch 115 MSE_tr: 1617378.125\n",
      "epoch 116 MSE_tr: 1617482.125\n",
      "epoch 117 MSE_tr: 1616762.25\n",
      "epoch 118 MSE_tr: 1616755.875\n",
      "epoch 119 MSE_tr: 1616729.75\n",
      "epoch 120 MSE_tr: 1616777.125\n",
      "epoch 121 MSE_tr: 1616949.75\n",
      "epoch 122 MSE_tr: 1616621.625\n",
      "epoch 123 MSE_tr: 1616620.25\n",
      "epoch 124 MSE_tr: 1617843.25\n",
      "epoch 125 MSE_tr: 1617782.625\n",
      "epoch 126 MSE_tr: 1616816.75\n",
      "epoch 127 MSE_tr: 1616896.125\n",
      "epoch 128 MSE_tr: 1617216.25\n",
      "epoch 129 MSE_tr: 1617042.875\n",
      "epoch 130 MSE_tr: 1616432.75\n",
      "epoch 131 MSE_tr: 1615846.0\n",
      "epoch 132 MSE_tr: 1617306.25\n",
      "epoch 133 MSE_tr: 1617421.25\n",
      "epoch 134 MSE_tr: 1617548.375\n",
      "epoch 135 MSE_tr: 1616525.375\n",
      "epoch 136 MSE_tr: 1616764.375\n",
      "epoch 137 MSE_tr: 1616701.25\n",
      "epoch 138 MSE_tr: 1615521.125\n",
      "epoch 139 MSE_tr: 1616214.625\n",
      "epoch 140 MSE_tr: 1617010.875\n",
      "epoch 141 MSE_tr: 1616506.5\n",
      "epoch 142 MSE_tr: 1616529.375\n",
      "epoch 143 MSE_tr: 1617134.0\n",
      "epoch 144 MSE_tr: 1616531.0\n",
      "epoch 145 MSE_tr: 1616712.0\n",
      "epoch 146 MSE_tr: 1616893.375\n",
      "epoch 147 MSE_tr: 1615248.75\n",
      "epoch 148 MSE_tr: 1617093.25\n",
      "epoch 149 MSE_tr: 1616958.125\n",
      "epoch 150 MSE_tr: 1616229.875\n",
      "epoch 151 MSE_tr: 1615965.125\n",
      "epoch 152 MSE_tr: 1616466.25\n",
      "epoch 153 MSE_tr: 1616546.625\n",
      "epoch 154 MSE_tr: 1616936.75\n",
      "epoch 155 MSE_tr: 1617397.875\n",
      "epoch 156 MSE_tr: 1617444.25\n",
      "epoch 157 MSE_tr: 1617345.625\n",
      "epoch 158 MSE_tr: 1615680.875\n",
      "epoch 159 MSE_tr: 1616832.875\n",
      "epoch 160 MSE_tr: 1615876.125\n",
      "epoch 161 MSE_tr: 1616612.75\n",
      "epoch 162 MSE_tr: 1616120.75\n",
      "epoch 163 MSE_tr: 1616823.875\n",
      "epoch 164 MSE_tr: 1615553.75\n",
      "epoch 165 MSE_tr: 1615736.5\n",
      "epoch 166 MSE_tr: 1616868.5\n",
      "epoch 167 MSE_tr: 1616384.375\n",
      "epoch 168 MSE_tr: 1617439.0\n",
      "epoch 169 MSE_tr: 1617371.25\n",
      "epoch 170 MSE_tr: 1616371.125\n",
      "epoch 171 MSE_tr: 1615741.875\n",
      "epoch 172 MSE_tr: 1615443.75\n",
      "epoch 173 MSE_tr: 1615460.25\n",
      "epoch 174 MSE_tr: 1616006.25\n",
      "epoch 175 MSE_tr: 1616028.0\n",
      "epoch 176 MSE_tr: 1616832.375\n",
      "epoch 177 MSE_tr: 1615937.0\n",
      "epoch 178 MSE_tr: 1616360.125\n",
      "epoch 179 MSE_tr: 1615365.75\n",
      "epoch 180 MSE_tr: 1615699.0\n",
      "epoch 181 MSE_tr: 1616610.75\n",
      "epoch 182 MSE_tr: 1615278.375\n",
      "epoch 183 MSE_tr: 1615192.125\n",
      "epoch 184 MSE_tr: 1614807.5\n",
      "epoch 185 MSE_tr: 1616361.625\n",
      "epoch 186 MSE_tr: 1615849.75\n",
      "epoch 187 MSE_tr: 1617041.125\n",
      "epoch 188 MSE_tr: 1616777.25\n",
      "epoch 189 MSE_tr: 1613994.0\n",
      "epoch 190 MSE_tr: 1615817.25\n",
      "epoch 191 MSE_tr: 1617053.375\n",
      "epoch 192 MSE_tr: 1616627.125\n",
      "epoch 193 MSE_tr: 1615496.625\n",
      "epoch 194 MSE_tr: 1615267.0\n",
      "epoch 195 MSE_tr: 1615159.125\n",
      "epoch 196 MSE_tr: 1615411.0\n",
      "epoch 197 MSE_tr: 1616329.125\n",
      "epoch 198 MSE_tr: 1617606.5\n",
      "epoch 199 MSE_tr: 1617194.875\n",
      "epoch 200 MSE_tr: 1616131.375\n",
      "epoch 201 MSE_tr: 1614656.625\n",
      "epoch 202 MSE_tr: 1615452.125\n",
      "epoch 203 MSE_tr: 1616321.125\n",
      "epoch 204 MSE_tr: 1616009.875\n",
      "epoch 205 MSE_tr: 1615699.625\n",
      "epoch 206 MSE_tr: 1615808.25\n",
      "epoch 207 MSE_tr: 1615678.25\n",
      "epoch 208 MSE_tr: 1615547.875\n",
      "epoch 209 MSE_tr: 1615197.125\n",
      "epoch 210 MSE_tr: 1616228.5\n",
      "epoch 211 MSE_tr: 1615547.375\n",
      "epoch 212 MSE_tr: 1614735.625\n",
      "epoch 213 MSE_tr: 1615584.75\n",
      "epoch 214 MSE_tr: 1615552.625\n",
      "epoch 215 MSE_tr: 1615030.375\n",
      "epoch 216 MSE_tr: 1615909.25\n",
      "epoch 217 MSE_tr: 1615182.875\n",
      "epoch 218 MSE_tr: 1615212.875\n",
      "epoch 219 MSE_tr: 1615931.625\n",
      "epoch 220 MSE_tr: 1616243.75\n",
      "epoch 221 MSE_tr: 1615964.625\n",
      "epoch 222 MSE_tr: 1615596.25\n",
      "epoch 223 MSE_tr: 1616062.25\n",
      "epoch 224 MSE_tr: 1615418.625\n",
      "epoch 225 MSE_tr: 1615633.125\n",
      "epoch 226 MSE_tr: 1615958.25\n",
      "epoch 227 MSE_tr: 1615449.75\n",
      "epoch 228 MSE_tr: 1614509.5\n",
      "epoch 229 MSE_tr: 1615429.375\n",
      "epoch 230 MSE_tr: 1615983.375\n",
      "epoch 231 MSE_tr: 1615201.0\n",
      "epoch 232 MSE_tr: 1615522.125\n",
      "epoch 233 MSE_tr: 1615514.625\n",
      "epoch 234 MSE_tr: 1615984.0\n",
      "epoch 235 MSE_tr: 1616509.875\n",
      "epoch 236 MSE_tr: 1616003.25\n",
      "epoch 237 MSE_tr: 1614037.625\n",
      "epoch 238 MSE_tr: 1616224.125\n",
      "epoch 239 MSE_tr: 1614836.75\n",
      "epoch 240 MSE_tr: 1615547.625\n",
      "epoch 241 MSE_tr: 1615987.75\n",
      "epoch 242 MSE_tr: 1616368.625\n",
      "epoch 243 MSE_tr: 1615980.375\n",
      "epoch 244 MSE_tr: 1615954.375\n",
      "epoch 245 MSE_tr: 1615782.125\n",
      "epoch 246 MSE_tr: 1615219.625\n",
      "epoch 247 MSE_tr: 1615412.875\n",
      "epoch 248 MSE_tr: 1615329.75\n",
      "epoch 249 MSE_tr: 1615203.375\n",
      "epoch 250 MSE_tr: 1615007.625\n",
      "epoch 251 MSE_tr: 1616244.875\n",
      "epoch 252 MSE_tr: 1617279.125\n",
      "epoch 253 MSE_tr: 1616528.375\n",
      "epoch 254 MSE_tr: 1614247.875\n",
      "epoch 255 MSE_tr: 1614660.875\n",
      "epoch 256 MSE_tr: 1614853.625\n",
      "epoch 257 MSE_tr: 1615889.125\n",
      "epoch 258 MSE_tr: 1616102.125\n",
      "epoch 259 MSE_tr: 1616424.125\n",
      "epoch 260 MSE_tr: 1616551.25\n",
      "epoch 261 MSE_tr: 1615729.375\n",
      "epoch 262 MSE_tr: 1615147.875\n",
      "epoch 263 MSE_tr: 1615459.5\n",
      "epoch 264 MSE_tr: 1614877.625\n",
      "epoch 265 MSE_tr: 1614718.75\n",
      "epoch 266 MSE_tr: 1616312.125\n",
      "epoch 267 MSE_tr: 1615733.875\n",
      "epoch 268 MSE_tr: 1615709.75\n",
      "epoch 269 MSE_tr: 1615557.25\n",
      "epoch 270 MSE_tr: 1614163.25\n",
      "epoch 271 MSE_tr: 1614813.25\n",
      "epoch 272 MSE_tr: 1614447.5\n",
      "epoch 273 MSE_tr: 1615158.375\n",
      "epoch 274 MSE_tr: 1616058.625\n",
      "epoch 275 MSE_tr: 1615310.625\n",
      "epoch 276 MSE_tr: 1614818.125\n",
      "epoch 277 MSE_tr: 1615164.0\n",
      "epoch 278 MSE_tr: 1614832.25\n",
      "epoch 279 MSE_tr: 1615256.875\n",
      "epoch 280 MSE_tr: 1616571.125\n",
      "epoch 281 MSE_tr: 1616123.5\n",
      "epoch 282 MSE_tr: 1615857.875\n",
      "epoch 283 MSE_tr: 1614942.75\n",
      "epoch 284 MSE_tr: 1614437.125\n",
      "epoch 285 MSE_tr: 1613930.25\n",
      "epoch 286 MSE_tr: 1614054.5\n",
      "epoch 287 MSE_tr: 1614374.0\n",
      "epoch 288 MSE_tr: 1614817.125\n",
      "epoch 289 MSE_tr: 1614773.5\n",
      "epoch 290 MSE_tr: 1614857.625\n",
      "epoch 291 MSE_tr: 1614539.5\n",
      "epoch 292 MSE_tr: 1615403.875\n",
      "epoch 293 MSE_tr: 1614542.75\n",
      "epoch 294 MSE_tr: 1614816.25\n",
      "epoch 295 MSE_tr: 1614277.75\n",
      "epoch 296 MSE_tr: 1615241.125\n",
      "epoch 297 MSE_tr: 1616229.875\n",
      "epoch 298 MSE_tr: 1615300.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12260/3611731113.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0ms_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;31m# trainloss = torch.sqrt(criterion(preds.to(device), data_train_MF.to(device)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtrainloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12260/1138671574.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# (2) hidden conv layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# t = F.max_pool2d(t, kernel_size=2, stride=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml2\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml2\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN 训练\n",
    "net = Network()\n",
    "# 损失\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "# loss = torch.sqrt(criterion(x, y))\n",
    "# 加载数据，设置优化器\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1,shuffle=False)\n",
    "# val_loader = torch.utils.data.DataLoader(train_set, batch_size=1,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,shuffle=True)\n",
    "# optimizer = torch.optim.Adam(net.parameters(),\n",
    "#         lr=0.00002)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "# lr_schedule = torch.optim.lr_scheduler.StepLR(\\\n",
    "#         optimizer, 1, gamma=0.8, last_epoch=-1)\n",
    "# 初始化 visdom \n",
    "viz.close()\n",
    "viz = viz_init()\n",
    "vislogDir = './/vislog_ndata//cnn//'\n",
    "if not os.path.exists(vislogDir):\n",
    "    os.makedirs(vislogDir)\n",
    "viz = Visdom(env=viz_acnt.evns, log_to_filename=vislogDir+'vislog_'+get_current_time())\n",
    "vizx = 0\n",
    "# viz.text('MONITOR: Show train process~~',win='Monitor', opts = {'title':'ProcessMonitor',},)\n",
    "\n",
    "# total_test_acc = 0\n",
    "# total_test_correct = 0\n",
    "# totaltest = 0\n",
    "# 训练过程\n",
    "epoch_num = 40000\n",
    "net.to(device)\n",
    "for epoch in range(epoch_num):\n",
    "    # 训练部分\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        s_x,s_y,s_a,s_t,s_i = batch\n",
    "        preds = net(s_x.to(device)) \n",
    "        # trainloss = torch.sqrt(criterion(preds.to(device), data_train_MF.to(device)))\n",
    "        trainloss = criterion(preds.to(device), s_y.to(device))\n",
    "        old_loss = trainloss\n",
    "        trainloss = new_loss3(preds.to(device),s_y.to(device),\\\n",
    "            s_t.to(device),s_i.to(device))\n",
    "        # trainloss.requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        # trainloss.backward(trainloss.clone().detach()) # Calculate Gradients\n",
    "        # with torch.autograd.detect_anomaly():\n",
    "        trainloss.backward()\n",
    "        # trainloss.backward(retain_graph=True)\n",
    "        optimizer.step() # Update Weight\n",
    "    # 定期展示当前的训练效果，即五个变量的 RMSE 值，用以挑选网络\n",
    "    predict_show = []\n",
    "    y_show = []\n",
    "    RMSE_list = [1.,2.,3.,4.,5.,6.]\n",
    "    val_loader = torch.utils.data.DataLoader(train_set, batch_size=1,shuffle=False)\n",
    "    net.eval()\n",
    "    net.to('cpu')\n",
    "    for batch in val_loader:\n",
    "        s_x,s_y,_,_,_ = batch\n",
    "        predict = net(s_x) \n",
    "        pred2 = predict.detach().numpy()\n",
    "        predict_show.append(pred2) \n",
    "        valloss = criterion(predict, s_y)\n",
    "        y_s = s_y.detach().numpy()\n",
    "        y_show.append(y_s)\n",
    "    predict_show = np.array(predict_show)\n",
    "    y_show = np.array(y_show)\n",
    "    for column in range(6):\n",
    "        RMSE_list[column] =  torch.sqrt(criterion(torch.Tensor(predict_show[:,:,column]), torch.Tensor(y_show[:,:,column])))\n",
    "    \n",
    "    viz.line([float(RMSE_list[0])],[vizx],win='MF&KA_RMSE', name='angle',\\\n",
    "        update='append',opts=dict(title='RMSE',xlabel='epoch',ylabel='RMSE',legend = ['angle','fcr','fcu','ecrl','ecrb','ecu']))\n",
    "    viz.line([float(RMSE_list[1])],[vizx],win='MF&KA_RMSE', name='fcr', update='append')\n",
    "    viz.line([float(RMSE_list[2])],[vizx],win='MF&KA_RMSE', name='fcu', update='append')\n",
    "    viz.line([float(RMSE_list[3])],[vizx],win='MF&KA_RMSE', name='ecrl', update='append')\n",
    "    viz.line([float(RMSE_list[4])],[vizx],win='MF&KA_RMSE', name='ecrb', update='append')\n",
    "    viz.line([float(RMSE_list[5])],[vizx],win='MF&KA_RMSE', name='ecu', update='append')\n",
    "\n",
    "    # 展示参数\n",
    "    if (epoch+1) % 1 ==0:\n",
    "        vizx+=1\n",
    "        print(\n",
    "            \"epoch\", epoch+1, \n",
    "            \"MSE_tr:\", float(trainloss),\n",
    "        )\n",
    "        viz.line([float(trainloss)],[vizx],win='loss_per_1_Epoch', name='Total_loss',\\\n",
    "            update='append',opts=dict(title='loss_per_1_Epoch',xlabel='1epoch',ylabel='loss'))\n",
    "        viz.line([float(old_loss)],[vizx],win='loss_per_1_Epoch', name='MSE_loss', update='append')\n",
    "        # viz.line([float(new_loss)],[vizx],win='new_loss_per_100_Epoch', name='New_loss',\\\n",
    "        #     update='append',opts=dict(title='new_loss_per 100 Epoch',xlabel='100 epoch',ylabel='loss'))\n",
    "        # viz.line([float(torch.sigmoid(new_loss))],[vizx],win='sig_new_loss_per_100_Epoch', name='New_loss',\\\n",
    "        #     update='append',opts=dict(title='sigmoid(new_loss)_per 100 Epoch',xlabel='100 epoch',ylabel='loss'))\n",
    "    # 定期保存\n",
    "    if (epoch+1)%1 == 0:\n",
    "        timeForSave = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "        checkpointPath = ckpDir+'emgsk_ep_'+str(epoch+1)+'_'+timeForSave+'.pth'\n",
    "        c_state = {'model': net.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n",
    "        torch.save(c_state, checkpointPath)\n",
    "\n",
    "# checkpointPath_model = model_Dir+'c_final_'+'acc'+str(int(total_test_acc*10000))+'_'+timeForSave+'.pth'\n",
    "checkpointPath_model = model_Dir+'kmmf_final_'+'_'+timeForSave+'.pth'\n",
    "torch.save(net.state_dict(),checkpointPath_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果展示\n",
    "展示训练效果，保存模型文件等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_x = data_1t6_te\n",
    "show_y = data_7t12_te\n",
    "show_l = 397\n",
    "column = 3\n",
    "net = net2\n",
    "net.eval()\n",
    "net.to('cpu')\n",
    "criterion = torch.nn.MSELoss()\n",
    "# predict = net(show_x)\n",
    "# predict = predict.data.numpy()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1,shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,shuffle=False)\n",
    "predict_show = []\n",
    "y_show = []\n",
    "for batch in test_loader:\n",
    "    s_x,s_y,_,_,_= batch\n",
    "    predict = net(s_x) \n",
    "    pred2 = predict.detach().numpy()\n",
    "    predict_show.append(pred2) \n",
    "    trainloss = criterion(predict, s_y)\n",
    "    y_s = s_y.detach().numpy()\n",
    "    y_show.append(y_s)\n",
    "predict_show = np.array(predict_show)\n",
    "y_show = np.array(y_show)\n",
    "# MSE_show = criterion(predict[:,column], show_y[:,column])\n",
    "MSE_show =  criterion(torch.Tensor(predict_show[:,:,column]), torch.Tensor(y_show[:,:,column]))\n",
    "predict = predict.data.numpy()\n",
    "# 建立等差数列，（起始，终止，个数）\n",
    "x = np.linspace(1,show_l,show_l)\n",
    "\n",
    "plt.title('mf_ecrl(RMSE:'+str('%.5g' % torch.sqrt(MSE_show))+')')\n",
    "# plt.plot(x , show_y[:,column], label='origin')\n",
    "plt.plot(x , show_y[:,column], label='origin')\n",
    "# plt.plot(x, predict[:,column], color='red', label='predict')\n",
    "plt.plot(x, predict_show[:,0,column], color='red', label='predict')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointPath_model = model_Dir+'emgsk_fornl_CNN_01'+'_nl_agle_re'+timeForSave+'.pth'\n",
    "# torch.save(net.state_dict(),checkpointPath_model)\n",
    "checkpointPath_model = model_Dir+'emgsk_nlv2'+'_onlyMSE_'+timeForSave+'.pth'\n",
    "torch.save(net.state_dict(),checkpointPath_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=6, bias=True)\n",
       "  (dr1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_for_net2 = torch.load(model_Dir+'emgsk_nlv2_onlyMSE_2022_04_10_20_22_21.pth')\n",
    "net2 = Network()\n",
    "net2.load_state_dict(checkpoint_for_net2)\n",
    "# net2.load_state_dict(checkpoint_for_net2['model'])\n",
    "net2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#对网络进行验证\n",
    "# column = 0\n",
    "# show_x = data_123_te\n",
    "# show_y = data_45_te_y\n",
    "# show_l = 20\n",
    "# net.eval()\n",
    "# net.to('cpu')\n",
    "# predict = net(show_x)\n",
    "# # predict = predict.data.numpy()\n",
    "\n",
    "# # MSE_show = criterion(predict[:,column], show_y[:,column])\n",
    "# MSE_show = criterion(predict, show_y)\n",
    "# predict = predict.data.numpy()\n",
    "# # 建立等差数列，（起始，终止，个数）\n",
    "# x = np.linspace(1,show_l,show_l)\n",
    "# # column = 0\n",
    "# plt.title('MF(RMSE:'+str('%.5g' % torch.sqrt(MSE_show))+')')\n",
    "# # plt.plot(x , show_y[:,column], label='origin')\n",
    "# plt.plot(x , show_y, label='origin')\n",
    "# # plt.plot(x, predict[:,column], color='red', label='predict')\n",
    "# plt.plot(x, predict, color='red', label='predict')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "122afd33e14e141e8feafe6109b3cf33c81901f42114774f6f58cb0f50546406"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
